
@inproceedings{taigman_deepface_2014,
	address = {Columbus, OH, USA},
	title = {{DeepFace}: {Closing} the {Gap} to {Human}-{Level} {Performance} in {Face} {Verification}},
	isbn = {978-1-4799-5118-5},
	shorttitle = {{DeepFace}},
	url = {https://ieeexplore.ieee.org/document/6909616},
	doi = {10.1109/CVPR.2014.220},
	abstract = {In modern face recognition, the conventional pipeline consists of four stages: detect ⇒ align ⇒ represent ⇒ classify. We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise afﬁne transformation, and derive a face representation from a nine-layer deep neural network. This deep network involves more than 120 million parameters using several locally connected layers without weight sharing, rather than the standard convolutional layers. Thus we trained it on the largest facial dataset to-date, an identity labeled dataset of four million facial images belonging to more than 4,000 identities. The learned representations coupling the accurate model-based alignment with the large facial database generalize remarkably well to faces in unconstrained environments, even with a simple classiﬁer. Our method reaches an accuracy of 97.35\% on the Labeled Faces in the Wild (LFW) dataset, reducing the error of the current state of the art by more than 27\%, closely approaching human-level performance.},
	language = {en},
	urldate = {2022-03-15},
	booktitle = {2014 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
	month = jun,
	year = {2014},
	pages = {1701--1708},
	file = {Taigman et al. - 2014 - DeepFace Closing the Gap to Human-Level Performan.pdf:C\:\\Users\\rosco\\Zotero\\storage\\6GNZZCEN\\Taigman et al. - 2014 - DeepFace Closing the Gap to Human-Level Performan.pdf:application/pdf},
}

@article{wang_deep_2021,
	title = {Deep {Face} {Recognition}: {A} {Survey}},
	volume = {429},
	issn = {09252312},
	shorttitle = {Deep {Face} {Recognition}},
	url = {http://arxiv.org/abs/1804.06655},
	doi = {10.1016/j.neucom.2020.10.081},
	abstract = {Deep learning applies multiple processing layers to learn representations of data with multiple levels of feature extraction. This emerging technique has reshaped the research landscape of face recognition (FR) since 2014, launched by the breakthroughs of DeepFace and DeepID. Since then, deep learning technique, characterized by the hierarchical architecture to stitch together pixels into invariant face representation, has dramatically improved the state-of-the-art performance and fostered successful real-world applications. In this survey, we provide a comprehensive review of the recent developments on deep FR, covering broad topics on algorithm designs, databases, protocols, and application scenes. First, we summarize different network architectures and loss functions proposed in the rapid evolution of the deep FR methods. Second, the related face processing methods are categorized into two classes: “one-to-many augmentation” and “many-to-one normalization”. Then, we summarize and compare the commonly used databases for both model training and evaluation. Third, we review miscellaneous scenes in deep FR, such as cross-factor, heterogenous, multiple-media and industrial scenes. Finally, the technical challenges and several promising directions are highlighted.},
	language = {en},
	urldate = {2022-03-15},
	journal = {Neurocomputing},
	author = {Wang, Mei and Deng, Weihong},
	month = mar,
	year = {2021},
	note = {arXiv: 1804.06655},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {215--244},
	annote = {Comment: Neurocomputing},
	file = {Wang and Deng - 2021 - Deep Face Recognition A Survey.pdf:C\:\\Users\\rosco\\Zotero\\storage\\A7JVRZ74\\Wang and Deng - 2021 - Deep Face Recognition A Survey.pdf:application/pdf},
}

@inproceedings{parkhi_deep_2015,
	address = {Swansea},
	title = {Deep {Face} {Recognition}},
	isbn = {978-1-901725-53-7},
	url = {http://www.bmva.org/bmvc/2015/papers/paper041/index.html},
	doi = {10.5244/C.29.41},
	abstract = {The goal of this paper is face recognition – from either a single photograph or from a set of faces tracked in a video. Recent progress in this area has been due to two factors: (i) end to end learning for the task using a convolutional neural network (CNN), and (ii) the availability of very large scale training datasets.},
	language = {en},
	urldate = {2022-03-15},
	booktitle = {Procedings of the {British} {Machine} {Vision} {Conference} 2015},
	publisher = {British Machine Vision Association},
	author = {Parkhi, Omkar M. and Vedaldi, Andrea and Zisserman, Andrew},
	year = {2015},
	pages = {41.1--41.12},
	file = {Parkhi et al. - 2015 - Deep Face Recognition.pdf:C\:\\Users\\rosco\\Zotero\\storage\\H6L5558C\\Parkhi et al. - 2015 - Deep Face Recognition.pdf:application/pdf},
}

@inproceedings{sun_deep_2014,
	address = {Columbus, OH, USA},
	title = {Deep {Learning} {Face} {Representation} from {Predicting} 10,000 {Classes}},
	isbn = {978-1-4799-5118-5},
	url = {https://ieeexplore.ieee.org/document/6909640},
	doi = {10.1109/CVPR.2014.244},
	abstract = {This paper proposes to learn a set of high-level feature representations through deep learning, referred to as Deep hidden IDentity features (DeepID), for face veriﬁcation. We argue that DeepID can be effectively learned through challenging multi-class face identiﬁcation tasks, whilst they can be generalized to other tasks (such as veriﬁcation) and new identities unseen in the training set. Moreover, the generalization capability of DeepID increases as more face classes are to be predicted at training. DeepID features are taken from the last hidden layer neuron activations of deep convolutional networks (ConvNets). When learned as classiﬁers to recognize about 10, 000 face identities in the training set and conﬁgured to keep reducing the neuron numbers along the feature extraction hierarchy, these deep ConvNets gradually form compact identity-related features in the top layers with only a small number of hidden neurons. The proposed features are extracted from various face regions to form complementary and over-complete representations. Any state-of-the-art classiﬁers can be learned based on these high-level representations for face veriﬁcation. 97.45\% veriﬁcation accuracy on LFW is achieved with only weakly aligned faces.},
	language = {en},
	urldate = {2022-03-16},
	booktitle = {2014 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Sun, Yi and Wang, Xiaogang and Tang, Xiaoou},
	month = jun,
	year = {2014},
	pages = {1891--1898},
	file = {Sun et al. - 2014 - Deep Learning Face Representation from Predicting .pdf:C\:\\Users\\rosco\\Zotero\\storage\\JF4Y3V2Z\\Sun et al. - 2014 - Deep Learning Face Representation from Predicting .pdf:application/pdf},
}
